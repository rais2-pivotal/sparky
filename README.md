# sparky
Tutorial notes for Spark

## Spark SQL
## +++++ +++

Processing engine which in contrast is better than Map/Reduce framework as there is no intermediate processing data written onto disk, 
everything happens in memory.

### SQL/DataFrame APIs/DataSets are various sources to Spark
- Initial phase generates a Query plan
- Catalyst (which is the core/Optimiser for Spark) Rewrites the plan in an Optimised fashion
  { Rewrite of a plan is nothing but set of trees rewritten efficiently}
- These Optimised query plans are then converted into set of RDDs to be executed in-parallel/sequential as required

### Trees explained:
- Are abstractions of users program, for instance:
```sql
  SELECT sum(v) FROM (SELECT t1.id, 1 + 2 + t1.value as v
   FROM t1 join t2 
   WHERE 
   t1.id = t2.id AND
   t2.id > 50000) tmp
```   
   
- Based on the above query, an expression represents a new value, computed based on input values.
  For instance, "1 + 2 + t1.value"
- Attribute, a column of a dataset e.g. "t1.id" Or a column generated by specific operation e.g. "as v"     
- In our case, all these are values for Catalyst optimizer/planner:
  - ```sum(v) ```
  - ```t1.id, 1 + 2 + t1.value as v```
  - ```t1.id = t2.id```
  - ```t2.id > 50000```
  

### Generic Query plan for this query
```sql
SELECT sum(v) FROM (SELECT t1.id, 1 + 2 + t1.value as v
  FROM t1 join t2 
  WHERE 
  t1.id = t2.id AND
  t2.id > 50000) tmp
```
Down-Up query plan would look something like this
- Phase 5: SCAN, scan(t1) and scan(t2)
- Phase 4: JOIN, t1 JOIN t2
- Phase 3: FILTER, t1.id = t2.id and t2.id > 50000
- Phase 2: PROJECTION, t1.id, 1+2+t1.value as v
- Phase 1: AGGREGATION, sum(v)

### Logical Plan

* Taking same query as example, logical plan describes computation on the datasets without defining how to conduct the computation
* Ouput, for instance ```t1.id and v (1+2+t1.value)```
* Constraints, for instance ```t2.id > 50000``` which are satisfied by the filter
* Statistics, min/max/ndv/nulls for each column. Also, size of the plan in rows/bytes

### Physical Plan

* Unlike logical plan, physical plan describes how the compute should be performed on the datasets
* Physical plan is executable, here is an illustration of physical plan for the same query

Down-Up query plan would look something like this
- Phase 5: SCAN, ```Parquet Scan(t1) and JSON scan(t2)```
- Phase 4: JOIN, ```Sort-Merge JOIN t1 JOIN t2```
- Phase 3: FILTER, ```t1.id = t2.id and t2.id > 50000```
- Phase 2: PROJECTION, ```t1.id, 1+2+t1.value as v```
- Phase 1: AGGREGATION, ```Hash-Aggregate sum(v)```




















#### Code formatting Link:
https://help.github.com/en/articles/creating-and-highlighting-code-blocks
